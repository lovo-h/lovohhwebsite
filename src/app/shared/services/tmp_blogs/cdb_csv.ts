import { hyphenFn } from './common';
import { Blog } from '../../class';


export const cdb_csv_blog = new Blog(
  'Importing CSV Data into CockroachDB',
  hyphenFn('Importing CSV Data into CockroachDB'),
  'Hector Lovo',
  'https://lovohh.com',
  'assets/imgs/blog/icdicdb/cdb_csv.png',
  'Backend',
  '05/21/2018',
  'This tutorial is going to demonstrate how to import CSV data into CockroachDB. According to the CockrochDB documentation, to be able to import CSV data, one must also have some kind of remote file server (such as Amazon S3 or a custom file server) that all the CockroachDB nodes can access. This tutorial uses the custom file server approach.',
  '<p>This short tutorial was written to demonstrate how easy it can be to import local CSV data into <em>CockroachDB</em>. Hopefully, this will save you some time if it\'s something you need to do for any of your projects. It should be noted that this tutorial utilizes <em>Docker</em> to help bypass some of <em>CockroachDB\'s</em> limitations. </p><p>Let\'s get started!</p><h3>Prerequisites</h3><p>To be able to follow along with this tutorial, the following tools will be required:</p><ul><li><a href="https://docs.docker.com/get-started/">Docker</a></li><li><a href="https://docs.docker.com/compose/gettingstarted/">Docker Compose</a></li></ul><p><strong>Note</strong>: If you would like to follow along with the code, <a href="https://github.com/lovo-h/cockroach_usdadb">the Github repository <strong>cockroach_usdadb</strong> can be found here</a>.</p><h3>Step 0. Get Setup</h3><p>Let\'s start by creating some structure for this project. We can begin by creating the following files and directories:</p><ul><li><code class="bt-dir">USDAFoodPopulator_CDB</code>: (directory) will be our root directory.</li><li>Inside <code class="bt-dir">USDAFoodPopulator_CDB</code>, let\'s add the following files and directories:<code></code><ul><li><code class="bt-dir">caddy_mnt</code>: (directory) will be used to store the CSV data files.<code></code></li><li><code class="bt-file">docker-compose.yml</code>: (file) will be used to configure the docker-containers.</li><li><code class="bt-file">Caddyfile</code>: (file) will be used to configure the file-server.</li></ul></li></ul><p>Now that we have some file-structure, let\'s move on to creating the schemas for the tables.</p><h3>Step 1. Create the Schemas</h3><p>To learn how these schemas were created, read <a href="blog/recreating-the-usda-national-nutrient-database-using-mssql-on-docker-part-1">Recreating the USDA National Nutrient Database Using MSSQL on Docker - Part 1</a> blog-post. Here\'s a quick reference-image for convenience:</p><p class="bt-img"><img src="assets/imgs/blog/icdicdb/usdafood_schema.png"></p><p>Note that there are some differences:</p><ol><li>This database will omit the FOOTNOTE table.</li><li>The WEIGHT table\'s <code>Amount</code> field will have a different width: 6 instead of 5.</li><li>The FOOD_DES table\'s <code>Shrt_Desc</code> will have a different length: 61 instead of 60.</li></ol><p>These changes were applied to support changes made to the data while converting it from a text (TXT) file to a comma separated values (CSV) file.</p><p>Using the schema-design from above and the <em>CockroachDB</em> docs, we know that we\'ll need the following <code>CREATE TABLE</code> statements:<code></code></p><pre class="bt-code"><code>CREATE TABLE data_src (</code><br /><code>\tdatasrc_id STRING(6) NOT NULL,</code><br /><code>\tauthors STRING(255) NULL,</code><br /><code>\ttitle STRING(255) NOT NULL,</code><br /><code>\tyear STRING(4) NULL,</code><br /><code>\tjournal STRING(135) NULL,</code><br /><code>\tvol_city STRING(16) NULL,</code><br /><code>\tissue_state STRING(5) NULL,</code><br /><code>\tstart_page STRING(5) NULL,</code><br /><code>\tend_page STRING(5) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (datasrc_id ASC),</code><br /><code>\tFAMILY "primary" (datasrc_id, authors, title, year, journal, vol_city, issue_state, start_page, end_page)</code><br /><code>);</code><br /><code><br />CREATE TABLE fd_group (</code><br /><code>\tfdgrp_cd STRING(4) NOT NULL,</code><br /><code>\tfdgrp_desc STRING(60) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (fdgrp_cd ASC),</code><br /><code>\tFAMILY "primary" (fdgrp_cd, fdgrp_desc)</code><br /><code>);<br /></code><br /><code>CREATE TABLE food_des (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tfdgrp_cd STRING(4) NOT NULL,</code><br /><code>\tlong_desc STRING(200) NOT NULL,</code><br /><code>\tshrt_desc STRING(61) NOT NULL,</code><br /><code>\tcomname STRING(100) NULL,</code><br /><code>\tmanufacname STRING(65) NULL,</code><br /><code>\tsurvey STRING(1) NULL,</code><br /><code>\tref_desc STRING(135) NULL,</code><br /><code>\trefuse INT NULL,</code><br /><code>\tsciname STRING(65) NULL,</code><br /><code>\tn_factor DECIMAL(4,2) NULL,</code><br /><code>\tpro_factor DECIMAL(4,2) NULL,</code><br /><code>\tfat_factor DECIMAL(4,2) NULL,</code><br /><code>\tcho_factor DECIMAL(4,2) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC),</code><br /><code>\tCONSTRAINT fk__food_des__fd_group FOREIGN KEY (fdgrp_cd) REFERENCES fd_group (fdgrp_cd) ON DELETE CASCADE,</code><br /><code>\tINDEX food_des_auto_index_fk__food_des__fd_group (fdgrp_cd ASC),</code><br /><code>\tFAMILY "primary" (ndb_no, fdgrp_cd, long_desc, shrt_desc, comname, manufacname, survey, ref_desc, refuse, sciname, n_factor, pro_factor, fat_factor, cho_factor)</code><br /><code>);</code><br /><br /><code>CREATE TABLE nutr_def (</code><br /><code>\tnutr_no STRING(3) NOT NULL,</code><br /><code>\tunits STRING(7) NOT NULL,</code><br /><code>\ttagname STRING(20) NULL,</code><br /><code>\tnutrdesc STRING(60) NOT NULL,</code><br /><code>\tnum_dec STRING(1) NOT NULL,</code><br /><code>\tsr_order INT NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (nutr_no ASC),</code><br /><code>\tFAMILY "primary" (nutr_no, units, tagname, nutrdesc, num_dec, sr_order)</code><br /><code>);</code><br /><code><br />CREATE TABLE src_cd (</code><br /><code>\tsrc_cd STRING(2) NOT NULL,</code><br /><code>\tsrccd_desc STRING(60) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (src_cd ASC),</code><br /><code>\tFAMILY "primary" (src_cd, srccd_desc)</code><br /><code>);</code><br /><br /><code>CREATE TABLE deriv_cd (</code><br /><code>\tderiv_cd STRING(4) NOT NULL,</code><br /><code>\tderiv_desc STRING(120) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (deriv_cd ASC),</code><br /><code>\tFAMILY "primary" (deriv_cd, deriv_desc)</code><br /><code>);</code><br /><code><br />CREATE TABLE nut_data (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tnutr_no STRING(3) NOT NULL,</code><br /><code>\tnutr_val DECIMAL(10,3) NOT NULL,</code><br /><code>\tnum_data_pts DECIMAL(5) NOT NULL,</code><br /><code>\tstd_error DECIMAL(8,3) NULL,</code><br /><code>\tsrc_cd STRING(2) NOT NULL,</code><br /><code>\tderiv_cd STRING(4) NULL,</code><br /><code>\tref_ndb_no STRING(5) NULL,</code><br /><code>\tadd_nutr_mark STRING(1) NULL,</code><br /><code>\tnum_studies INT NULL,</code><br /><code>\tmin DECIMAL(10,3) NULL,</code><br /><code>\tmax DECIMAL(10,3) NULL,</code><br /><code>\tdf INT NULL,</code><br /><code>\tlow_eb DECIMAL(10,3) NULL,</code><br /><code>\tup_eb DECIMAL(10,3) NULL,</code><br /><code>\tstat_cmt STRING(10) NULL,</code><br /><code>\taddmod_date STRING(10) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, nutr_no ASC),</code><br /><code>\tCONSTRAINT fk__nut_data__nutr_def FOREIGN KEY (nutr_no) REFERENCES nutr_def (nutr_no) ON DELETE CASCADE,</code><br /><code>\tINDEX nut_data_auto_index_fk__nut_data__nutr_def (nutr_no ASC),</code><br /><code>\tCONSTRAINT fk__nut_data__src_cd FOREIGN KEY (src_cd) REFERENCES src_cd (src_cd) ON DELETE CASCADE,</code><br /><code>\tINDEX nut_data_auto_index_fk__nut_data__src_cd (src_cd ASC),</code><br /><code>\tCONSTRAINT fk__nut_data__deriv_cd FOREIGN KEY (deriv_cd) REFERENCES deriv_cd (deriv_cd) ON DELETE CASCADE,</code><br /><code>\tINDEX nut_data_auto_index_fk__nut_data__deriv_cd (deriv_cd ASC),</code><br /><code>\tCONSTRAINT fk__nut_data__food_des FOREIGN KEY (ndb_no) REFERENCES food_des (ndb_no) ON DELETE CASCADE,</code><br /><code>\tFAMILY "primary" (ndb_no, nutr_no, nutr_val, num_data_pts, std_error, src_cd, deriv_cd, ref_ndb_no, add_nutr_mark, num_studies, min, max, df, low_eb, up_eb, stat_cmt, addmod_date)</code><br /><code>);</code><br /><code><br />CREATE TABLE datsrcln (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tnutr_no STRING(3) NOT NULL,</code><br /><code>\tdatasrc_id STRING(6) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, nutr_no ASC, datasrc_id ASC),</code><br /><code>\tCONSTRAINT fk__datsrcln__data_src FOREIGN KEY (datasrc_id) REFERENCES data_src (datasrc_id) ON DELETE CASCADE,</code><br /><code>\tINDEX datsrcln_auto_index_fk__datsrcln__data_src (datasrc_id ASC),</code><br /><code>\tCONSTRAINT fk__datsrcln__nut_data FOREIGN KEY (ndb_no, nutr_no) REFERENCES nut_data (ndb_no, nutr_no) ON DELETE CASCADE,</code><br /><code>\tFAMILY "primary" (ndb_no, nutr_no, datasrc_id)</code><br /><code>);</code><br /><br /><code>CREATE TABLE langdesc (</code><br /><code>\tfactor_code STRING(5) NOT NULL,</code><br /><code>\tdescription STRING(140) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (factor_code ASC),</code><br /><code>\tFAMILY "primary" (factor_code, description)</code><br /><code>);</code><br /><code><br />CREATE TABLE langual (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tfactor_code STRING(5) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, factor_code ASC),</code><br /><code>\tCONSTRAINT fk__langual__langdesc FOREIGN KEY (factor_code) REFERENCES langdesc (factor_code) ON DELETE CASCADE,</code><br /><code>\tINDEX langual_auto_index_fk__langual__langdesc (factor_code ASC),</code><br /><code>\tCONSTRAINT fk__langual__food_des FOREIGN KEY (ndb_no) REFERENCES food_des (ndb_no) ON DELETE CASCADE,</code><br /><code>\tFAMILY "primary" (ndb_no, factor_code)</code><br /><code>);</code><br /><br /><code>CREATE TABLE weight (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tseq STRING(2) NOT NULL,</code><br /><code>\tamount DECIMAL(6,3) NOT NULL,</code><br /><code>\tmsre_desc STRING(84) NOT NULL,</code><br /><code>\tgm_wgt DECIMAL(7,1) NOT NULL,</code><br /><code>\tnum_data_pts INT NULL,</code><br /><code>\tstd_dev DECIMAL(7,3) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, seq ASC),</code><br /><code>\tCONSTRAINT fk__weight__food_des FOREIGN KEY (ndb_no) REFERENCES food_des (ndb_no) ON DELETE CASCADE,</code><br /><code>\tFAMILY "primary" (ndb_no, seq, amount, msre_desc, gm_wgt, num_data_pts, std_dev)</code><br /><code>);</code><code></code></pre><p>To learn more about the keywords used to create these SQL-commands, here are some relevant <em>CockroachDB</em> doc-links:</p><ul><li><a href="https://www.cockroachlabs.com/docs/stable/create-table.html">CREATE TABLE docs</a>: creates a new table in a database.</li><li><a href="https://www.cockroachlabs.com/docs/stable/data-types.html">DATA TYPES docs</a>: data-types that <em>CockroachDB</em> supports.</li><li><a href="https://www.cockroachlabs.com/docs/stable/constraints.html">CONSTRAINTS docs</a>: offer additional data integrity by enforcing conditions on the data within a column.</li><li><a href="https://www.cockroachlabs.com/docs/stable/column-families.html">FAMILY docs</a>: a group of columns in a table that are stored as a single key-value pair in the underlying key-value store.</li></ul><p>Next, let\'s retrieve the CSV data that will be imported into the <em>CockroachDB</em> database.</p><h3>Step 2. Download the CSV Data</h3><p>The CSV files can be downloaded from the <em>Github</em> repository for this tutorial. <a href="https://github.com/lovo-h/cockroach_usdadb/blob/master/caddy_mnt/usdafooddb_csv.zip">Click here to download the CSV files in a ZIP file</a>.</p><p>Once the CSV files have been downloaded and extracted from the ZIP file, place them in the <code class="bt-dir">./caddy_mnt</code> directory. Notice that even though this tutorial will not be using the data for the FOOTNOTE table, it is still provided in the ZIP file for convenience.</p><h3>Step 3. Create the Default CockroachDB Server and the File-Server</h3><p>For this step, we will be creating a <em>Caddy</em> file-server. <a href="https://www.cockroachlabs.com/docs/stable/create-a-file-server.html#using-caddy-as-a-file-server">See the CockroachDB documentation for more information on how to create a Caddy file-server</a>.</p><p>According to the documentation, to create a <em>Caddy</em> file-server, the following two conditions are needed:</p><ol><li>Caddy with the <a href="https://caddyserver.com/docs/http.upload">http.upload plugin</a></li><li>Caddy running and configured - either through a command-line or a <a href="https://caddyserver.com/docs/caddyfile">Caddyfile</a></li></ol><p>To facilitate this process, we will be using <em>Docker</em> and a <em>Docker Compose</em> file. </p><p>Let\'s begin by retrieving a <em>Caddy</em> instance with the <em>http.upload</em> plugin. According to the <a href="https://github.com/abiosoft/caddy-docker#custom-plugins">Caddy documentation on custom-plugins</a>, this can be accomplished by opening a new terminal window and running the following command:</p><pre class="bt-cmd-in"><code>docker build --build-arg plugins=upload --tag caddy_upload github.com/abiosoft/caddy-docker.git</code></pre><p>Let\'s verify that we successfully created the image by running the following command:</p><pre class="bt-cmd-in"><code>docker images</code></pre><p>We expect to see something similar to the following:</p><pre class="bt-cmd-out"><code>REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</code><br /><code>caddy_upload        latest              61aedd1428b4        2 minutes ago       45.1MB<br />... </code></pre><p>Notice that the image is named <code>caddy_upload</code> as expected. This fulfills the first requirement: "Caddy with the http.upload plugin." Now, let\'s configure and boot up the <em>Caddy</em> image.</p><p>For this part, we will be using <em>Docker Compose</em> to help configure the <em>Docker</em> image. So, let\'s begin by adding the following to the <code class="bt-file">./docker-compose.yml</code> file:</p><pre class="bt-code"><code>version: "3"<br /></code><code>services:</code><br /><code>  cockroach-usdadb:</code><br /><code>    image: cockroachdb/cockroach</code><br /><code>    container_name: cockroach_usdadb</code><br /><code>    command: start --insecure</code><br /><code>    ports:</code><br /><code>      - 8080:8080</code><br /><code>    links:</code><br /><code>      - caddy-fileserver</code><br /><code>  caddy-fileserver:</code><br /><code>    image: caddy_upload</code><br /><code>    container_name: caddy_fileserver</code><br /><code>    ports:</code><br /><code>      - 2015:2015</code><br /><code>    volumes:</code><br /><code>      - ./caddy_mnt/:/srv/</code><br /><code>      - ./Caddyfile:/etc/Caddyfile</code><br /><code>      - ${HOME}/.caddy:/root/.caddy</code><br /><code>    environment:</code><br /><code>      - ACME_AGREE=true</code></pre><p>Here\'s a list of the changes made to the <code class="bt-file">docker-compose.yml</code> file:</p><ul><li>We created two services: <code>cockroach-usdadb</code> and <code>caddy-fileserver</code>.</li><li>The <code>cockroach-usdadb</code> service does the following:<ul><li>Uses the <em>Docker</em> image: <code><a href="https://hub.docker.com/r/cockroachdb/cockroach/">cockroachdb/cockroach</a></code>.</li><li>Names the <em>Docker</em> container: <code>cockroach_usdadb</code> for easier reference.</li><li>Sets the command that <code>cockroach_usdadb</code> will run at boot to: <code>start --insecure</code>. This command simply boots up <em>CockroachDB</em> in an insecure manner.</li><li>Maps the host\'s port <code>8080</code> to the container\'s port <code>8080</code>.</li><li>Links to the <code>caddy-filserver</code> for easier reference.</li><li><a href="https://www.cockroachlabs.com/docs/stable/start-a-local-cluster-in-docker.html">See the CockroachDB documentation for more information related to the Docker image</a>.</li></ul></li><li><code>caddy-fileserver</code><ul><li>Uses the <em>Docker</em> image: <code>caddy_upload</code> (the one we created earlier in this step).</li><li>Names the <em>Docker</em> container: <code>caddy_fileserver</code> for easier reference.</li><li>Maps the host\'s port <code>2015</code> to the container\'s port <code>2015</code>.</li><li>Maps the following files and directories from the host to the container:<ul><li>Directory: <code>./caddy_mnt &rarr; /srv/</code>. Allows the container to access the CSV files in the host.</li><li>File: <code>./Caddyfile &rarr; /etc/Caddyfile</code>. Used to configure the Caddy server.</li><li>Directory: <code>${HOME}/.caddy &rarr; /root/.caddy</code>. Saves the certificates on the host machine to prevent regeneration every time the container starts.</li></ul></li><li>Sets the environment variable <code>ACME_AGREE</code> to <code>true</code>. In case Caddy prompts one to agree to <a href="https://letsencrypt.org/documents/2017.11.15-LE-SA-v1.2.pdf">Let\'s Encrypt Subscriber Agreement</a>.</li><li><a href="https://hub.docker.com/r/abiosoft/caddy/">See the abiosoft/caddy documentation for more information on this Docker image</a>.</li></ul></li></ul><p>Notice that the <code>caddy-fileserver</code> service maps the <code class="bt-file">Caddyfile</code> file from the host to the container. But, as of now, the <code class="bt-file">Caddyfile</code> file is empty so let\'s add the following:</p><pre class="bt-code"><code>0.0.0.0:2015 {</code><br /><code>    upload / {</code><br /><code>      to "/srv/"</code><br /><code>      yes_without_tls</code><br /><code>    }</code><br /><code>}</code></pre><p>A quick rundown of what this configuration does:</p><ul><li><code>0.0.0.0:2015</code>: defines the address of the file-server. Recall that we mapped port <code>2015</code> from the host to <code>caddy_fileserver</code> container.</li><li><code>upload /</code>: defines the scope for which the <code>upload</code> plugin will react towards. In this case, it will react to <a href="http://0.0.0.0:2015/">http://0.0.0.0:2015/</a>. For <a href="https://hub.blitznote.com/src/caddy.upload/blob/master/README.md">more information on the upload plugin, see the documentation</a>.</li><li><code>to "/srv/"</code>: defines the target directory: <code>/srv/</code>, in this case. Recall that we are mapping the CSV files to this directory.</li><li><code>yes_without_tls</code>: tells <em>Caddy</em> not to use TLS.</li><li><a href="https://caddyserver.com/tutorial/caddyfile">Read the Caddyfile Primer for more information on how to configure the Caddyfile</a>.</li></ul><p>Let\'s verify that everything has been configured accordingly. Reopen the terminal window and navigate to the <code class="bt-dir">./USDAFoodPopulator_CDB</code> directory. Then, run the following command:</p><pre class="bt-cmd-in"><code>docker-compose up</code></pre><p>If this is the first time running this command on this <code class="bt-file">docker-compose.yml</code> file, expect to see something similar to the following command-line output:</p><pre class="bt-cmd-out"><code>Creating network "usdafoodpopulator_cdb_default" with the default driver</code><br /><code>Pulling cockroach-usdadb (cockroachdb/cockroach:)...</code><br /><code>latest: Pulling from cockroachdb/cockroach</code><br /><code>85b1f47fba49: Pull complete</code><br /><code>7eeb8e93831d: Pull complete</code><br /><code>22244e5f689d: Pull complete</code><br /><code>7460898ebdb2: Pull complete</code><br /><code>Digest: sha256:51bd1ed6b5fa881c61a0ba1232782649681d3ba699613d454a4bd6f7edbeb236</code><br /><code>Status: Downloaded newer image for cockroachdb/cockroach:latest</code><br /><code>Creating cockroach_usdadb ... done</code><br /><code>Creating caddy_fileserver ... done</code><br /><code>Attaching to cockroach_usdadb, caddy_fileserver</code><br /><code>cockroach_usdadb    | *</code><br /><code>cockroach_usdadb    | * WARNING: RUNNING IN INSECURE MODE!</code><br /><code>cockroach_usdadb    | * </code><br /><code>cockroach_usdadb    | * - Your cluster is open for any client that can access &lt;all your IP addresses&gt;.</code><br /><code>cockroach_usdadb    | * - Any user, even root, can log in without providing a password.</code><br /><code>cockroach_usdadb    | * - Any user, connecting as root, can read or write any data in your cluster.</code><br /><code>cockroach_usdadb    | * - There is no network encryption nor authentication, and thus no confidentiality.</code><br /><code>cockroach_usdadb    | * </code><br /><code>cockroach_usdadb    | * Check out how to secure your cluster: https://www.cockroachlabs.com/docs/v2.0/secure-a-cluster.html</code><br /><code>cockroach_usdadb    | *</code><br /><code>caddy_fileserver    | Activating privacy features... done.</code><br /><code>caddy_fileserver    | 2018/06/06 03:11:34 Version of plugin \'upload\': c5471f2e-03095b13-6bc856cf</code><br /><code>caddy_fileserver    | http://0.0.0.0:2015</code><br /><code>caddy_fileserver    | 2018/06/06 03:11:34 http://0.0.0.0:2015</code><br /><code>caddy_fileserver    | 2018/06/06 03:11:34 [INFO] Sending telemetry: success</code><br /><code>cockroach_usdadb    | CockroachDB node starting at 2018-06-06 03:11:35.49299279 +0000 UTC (took 0.9s)</code><br /><code>cockroach_usdadb    | build:               CCL v2.0.2 @ 2018/05/21 14:55:20 (go1.10)</code><br /><code>cockroach_usdadb    | admin:               http://94fe029a8614:8080</code><br /><code>cockroach_usdadb    | sql:                 postgresql://root@94fe029a8614:26257?sslmode=disable</code><br /><code>cockroach_usdadb    | logs:                /cockroach/cockroach-data/logs</code><br /><code>cockroach_usdadb    | temp dir:            /cockroach/cockroach-data/cockroach-temp438089660</code><br /><code>cockroach_usdadb    | external I/O path:   /cockroach/cockroach-data/extern</code><br /><code>cockroach_usdadb    | store[0]:            path=/cockroach/cockroach-data</code><br /><code>cockroach_usdadb    | status:              initialized new cluster</code><br /><code>cockroach_usdadb    | clusterID:           b14f0255-6109-41e1-90ed-e65eca36fd97</code><br /><code>cockroach_usdadb    | nodeID:              1</code></pre><p>Now, navigate to <a href="http://localhost:2015/DATA_SRC.csv">http://localhost:2015/DATA_SRC.csv</a>. If you are able to access the <code>DATA_SRC.csv</code> file successfully, everything was configured accordingly!</p><p>Next, we will create the <code>IMPORT</code> statements and run them in the <em>CockroachDB</em> container. But, before moving forward:</p><ul><li>Open a new terminal window (or tab).</li><li>Navigate this new terminal window to the <code class="bt-dir">./USDAFoodPopulator_CDB</code> directory.</li><li>And leave this terminal window up-and-running for the next step.</li></ul><h3>Step 4. Create &amp; Run the Import-Statements</h3><p>Before we begin, let\'s <a href="https://www.cockroachlabs.com/docs/stable/import.html">reference the CockroachDB docs for the import statement</a> to determine how to write these statements. In particular, <a href="https://www.cockroachlabs.com/docs/stable/import.html#synopsis">pay close attention to the Synopsis in the docs</a>, posted here for convenience:</p><p class="bt-img"><img src="assets/imgs/blog/icdicdb/import_synopsis.png"></p><p>Using the synopsis, we know that the <code>IMPORT</code> statements will look something akin to the following:</p><pre class="bt-code"><code>IMPORT TABLE <span class="bt-highlight-code">table_name</span> (<br />  <span class="bt-highlight-code">table_elem_list</span><br />) CSV DATA (\'http://caddy-fileserver:2015/<span class="bt-highlight-code">&lt;file.csv&gt;</span>\') <br />WITH DELIMITER = \',\', nullif = \'\';</code></pre><p>In this statement, notice that the URL contains the service <code>caddy-fileserver</code>\'s name. This can be done because the <em>CockroachDB</em> container <code>cockroach-usdadb</code> is linked to the <em>Caddy</em> container <code>caddy-fileserver</code> in the <code class="bt-file">./docker-compose.yml</code> file.</p><p>Using the above statement as a template, we get the following <code>IMPORT</code> statements:</p><pre class="bt-code"><code>IMPORT TABLE data_src (</code><br /><code>\tdatasrc_id STRING(6) NOT NULL,</code><br /><code>\tauthors STRING(255) NULL,</code><br /><code>\ttitle STRING(255) NOT NULL,</code><br /><code>\tyear STRING(4) NULL,</code><br /><code>\tjournal STRING(135) NULL,</code><br /><code>\tvol_city STRING(16) NULL,</code><br /><code>\tissue_state STRING(5) NULL,</code><br /><code>\tstart_page STRING(5) NULL,</code><br /><code>\tend_page STRING(5) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (datasrc_id ASC),</code><br /><code>\tFAMILY "primary" (datasrc_id, authors, title, year, journal, vol_city, issue_state, start_page, end_page)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/DATA_SRC.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE fd_group (</code><br /><code>\tfdgrp_cd STRING(4) NOT NULL,</code><br /><code>\tfdgrp_desc STRING(60) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (fdgrp_cd ASC),</code><br /><code>\tFAMILY "primary" (fdgrp_cd, fdgrp_desc)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/FD_GROUP.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE food_des (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tfdgrp_cd STRING(4) NOT NULL,</code><br /><code>\tlong_desc STRING(200) NOT NULL,</code><br /><code>\tshrt_desc STRING(61) NOT NULL,</code><br /><code>\tcomname STRING(100) NULL,</code><br /><code>\tmanufacname STRING(65) NULL,</code><br /><code>\tsurvey STRING(1) NULL,</code><br /><code>\tref_desc STRING(135) NULL,</code><br /><code>\trefuse INT NULL,</code><br /><code>\tsciname STRING(65) NULL,</code><br /><code>\tn_factor DECIMAL(4,2) NULL,</code><br /><code>\tpro_factor DECIMAL(4,2) NULL,</code><br /><code>\tfat_factor DECIMAL(4,2) NULL,</code><br /><code>\tcho_factor DECIMAL(4,2) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC),</code><br /><code>\tINDEX food_des_auto_index_fk__food_des__fd_group (fdgrp_cd ASC),</code><br /><code>\tFAMILY "primary" (ndb_no, fdgrp_cd, long_desc, shrt_desc, comname, manufacname, survey, ref_desc, refuse, sciname, n_factor, pro_factor, fat_factor, cho_factor)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/FOOD_DES.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE nutr_def (</code><br /><code>\tnutr_no STRING(3) NOT NULL,</code><br /><code>\tunits STRING(7) NOT NULL,</code><br /><code>\ttagname STRING(20) NULL,</code><br /><code>\tnutrdesc STRING(60) NOT NULL,</code><br /><code>\tnum_dec STRING(1) NOT NULL,</code><br /><code>\tsr_order INT NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (nutr_no ASC),</code><br /><code>\tFAMILY "primary" (nutr_no, units, tagname, nutrdesc, num_dec, sr_order)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/NUTR_DEF.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE src_cd (</code><br /><code>\tsrc_cd STRING(2) NOT NULL,</code><br /><code>\tsrccd_desc STRING(60) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (src_cd ASC),</code><br /><code>\tFAMILY "primary" (src_cd, srccd_desc)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/SRC_CD.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE deriv_cd (</code><br /><code>\tderiv_cd STRING(4) NOT NULL,</code><br /><code>\tderiv_desc STRING(120) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (deriv_cd ASC),</code><br /><code>\tFAMILY "primary" (deriv_cd, deriv_desc)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/DERIV_CD.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE nut_data (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tnutr_no STRING(3) NOT NULL,</code><br /><code>\tnutr_val DECIMAL(10,3) NOT NULL,</code><br /><code>\tnum_data_pts DECIMAL(5) NOT NULL,</code><br /><code>\tstd_error DECIMAL(8,3) NULL,</code><br /><code>\tsrc_cd STRING(2) NOT NULL,</code><br /><code>\tderiv_cd STRING(4) NULL,</code><br /><code>\tref_ndb_no STRING(5) NULL,</code><br /><code>\tadd_nutr_mark STRING(1) NULL,</code><br /><code>\tnum_studies INT NULL,</code><br /><code>\tmin DECIMAL(10,3) NULL,</code><br /><code>\tmax DECIMAL(10,3) NULL,</code><br /><code>\tdf INT NULL,</code><br /><code>\tlow_eb DECIMAL(10,3) NULL,</code><br /><code>\tup_eb DECIMAL(10,3) NULL,</code><br /><code>\tstat_cmt STRING(10) NULL,</code><br /><code>\taddmod_date STRING(10) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, nutr_no ASC),</code><br /><code>\tINDEX nut_data_auto_index_fk__nut_data__nutr_def (nutr_no ASC),</code><br /><code>\tINDEX nut_data_auto_index_fk__nut_data__src_cd (src_cd ASC),</code><br /><code>\tINDEX nut_data_auto_index_fk__nut_data__deriv_cd (deriv_cd ASC),</code><br /><code>\tFAMILY "primary" (ndb_no, nutr_no, nutr_val, num_data_pts, std_error, src_cd, deriv_cd, ref_ndb_no, add_nutr_mark, num_studies, min, max, df, low_eb, up_eb, stat_cmt, addmod_date)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/NUT_DATA.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE datsrcln (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tnutr_no STRING(3) NOT NULL,</code><br /><code>\tdatasrc_id STRING(6) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, nutr_no ASC, datasrc_id ASC),</code><br /><code>\tINDEX datsrcln_auto_index_fk__datsrcln__data_src (datasrc_id ASC),</code><br /><code>\tFAMILY "primary" (ndb_no, nutr_no, datasrc_id)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/DATSRCLN.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE langdesc (</code><br /><code>\tfactor_code STRING(5) NOT NULL,</code><br /><code>\tdescription STRING(140) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (factor_code ASC),</code><br /><code>\tFAMILY "primary" (factor_code, description)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/LANGDESC.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE langual (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tfactor_code STRING(5) NOT NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, factor_code ASC),</code><br /><code>\tINDEX langual_auto_index_fk__langual__langdesc (factor_code ASC),</code><br /><code>\tFAMILY "primary" (ndb_no, factor_code)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/LANGUAL.csv\') WITH DELIMITER = \',\', nullif = \'\';</code><br /><br /><code>IMPORT TABLE weight (</code><br /><code>\tndb_no STRING(5) NOT NULL,</code><br /><code>\tseq STRING(2) NOT NULL,</code><br /><code>\tamount DECIMAL(6,3) NOT NULL,</code><br /><code>\tmsre_desc STRING(84) NOT NULL,</code><br /><code>\tgm_wgt DECIMAL(7,1) NOT NULL,</code><br /><code>\tnum_data_pts INT NULL,</code><br /><code>\tstd_dev DECIMAL(7,3) NULL,</code><br /><code>\tCONSTRAINT "primary" PRIMARY KEY (ndb_no ASC, seq ASC),</code><br /><code>\tFAMILY "primary" (ndb_no, seq, amount, msre_desc, gm_wgt, num_data_pts, std_dev)</code><br /><code>) CSV DATA (\'http://caddy-fileserver:2015/WEIGHT.csv\') WITH DELIMITER = \',\', nullif = \'\';</code></pre><p>Notice that the <code>FOREIGN KEY</code> constraints were omitted from these <code>IMPORT</code> statements. This is due to the fact that they are not supported by the <code>IMPORT</code> statement so they will need to be re-added in <strong>Step 5</strong>.</p><p>Next, we need to run these <code>IMPORT</code> statements in the <em>CockroachDB</em> container. So, in the second terminal window that you opened at the end of <strong>Step 3</strong>, run the following command:</p><pre class="bt-cmd-in"><code>docker exec -it cockroach_usdadb ./cockroach sql --insecure</code></pre><p>If the command ran successfully, expect to see output similar to the following:</p><pre class="bt-cmd-out"><code># Welcome to the cockroach SQL interface.</code><br /><code># All statements must be terminated by a semicolon.</code><br /><code># To exit: CTRL + D.</code><br /><code>#</code><br /><code># Server version: CockroachDB CCL v2.0.2 (x86_64-unknown-linux-gnu, built 2018/05/21 14:55:20, go1.10) (same version as client)</code><br /><code># Cluster ID: e6227d78-1978-423f-9fd0-b89a0e785aad</code><br /><code>#</code><br /><code># Enter \\? for a brief introduction.</code><br /><code>#</code><br /><code>warning: no current database set. Use SET database = &lt;dbname&gt; to change, CREATE DATABASE to make a new database.</code><br /><code>root@:26257/&gt;</code><br /><code></code></pre><p>We now have a session that connects the host machine to the <em>Cockroach SQL interface</em> in the container <code>cockroach_usdadb</code>. From here, we can run SQL statements.</p><p>Let\'s start by creating the database by running the following command in the interface:</p><pre class="bt-cmd-in"><code>CREATE DATABASE usdafooddb;</code></pre><p>Set the <code>usdafooddb</code> as the current database with the following command:</p><pre class="bt-cmd-in"><code>SET DATABASE=usdafooddb;</code></pre><p>Now, paste all of the import statements into the interface and  press <code>Enter</code> on the keyboard. If everything is configured correctly, expect to see something similar to the following command-line output:</p><pre class="bt-cmd-out"><code>+--------------------+-----------+--------------------+------+---------------+----------------+-------+</code><br /><code>|       job_id       |  status   | fraction_completed | rows | index_entries | system_records | bytes |</code><br /><code>+--------------------+-----------+--------------------+------+---------------+----------------+-------+</code><br /><code>| 355071093959524353 | succeeded |                  1 |    0 |             0 |              0 |     0 |</code><br /><code>+--------------------+-----------+--------------------+------+---------------+----------------+-------+</code><br /><code>(1 row)</code><br /><br /><code>Time: 15.971308145s</code><br /><br /><code>+--------------------+-----------+--------------------+------+---------------+----------------+-------+</code><br /><code>|       job_id       |  status   | fraction_completed | rows | index_entries | system_records | bytes |</code><br /><code>+--------------------+-----------+--------------------+------+---------------+----------------+-------+</code><br /><code>| 355071094957441025 | succeeded |                  1 |    0 |             0 |              0 |     0 |</code><br /><code>+--------------------+-----------+--------------------+------+---------------+----------------+-------+</code><br /><code>(1 row)</code><br /><br /><code>Time: 3.43975ms</code><br /><br />...</pre><p>Also, if we run the following command:</p><pre class="bt-cmd-in"><code>SHOW TABLES;</code></pre><p>Expect the following output:</p><pre class="bt-cmd-out"><code>+----------+</code><br /><code>| Table    |</code><br /><code>+----------+</code><br /><code>| data_src |</code><br /><code>| datsrcln |</code><br /><code>| deriv_cd |</code><br /><code>| fd_group |</code><br /><code>| food_des |</code><br /><code>| langdesc |</code><br /><code>| langual  |</code><br /><code>| nut_data |</code><br /><code>| nutr_def |</code><br /><code>| src_cd   |</code><br /><code>| weight   |</code><br /><code>+----------+</code><br /><code>(11 rows)</code><br /><br /><code>Time: 5.470317ms</code></pre><p>Next, let\'s add in the foreign-key constraints.</p><h3>Step 5. Add in the Foreign-Key Constraints</h3><p>According to <a href="https://www.cockroachlabs.com/docs/stable/add-constraint.html#add-the-foreign-key-constraint-with-cascade">the docs on adding foreign key constraints with cascade</a>, before we can add the foreign key constraint, the columns must first be indexed. Fortunately, we already indexed the columns when we ran the <code>IMPORT</code> statements in <strong>Step 4 </strong>so we need not worry about that.</p><p>To recreate the foreign-key constraints, let\'s use the following template:</p><pre class="bt-code"><code>ALTER TABLE <span class="bt-highlight-code">table_name</span> \\</code><br /><code>ADD CONSTRAINT <span class="bt-highlight-code">fk_label</span> \\</code><br /><code>FOREIGN KEY (<span class="bt-highlight-code">fk_col_name</span>) \\</code><br /><code>REFERENCES <span class="bt-highlight-code">fktable_name</span> (<span class="bt-highlight-code">fktable_col_name</span>) ON DELETE CASCADE;</code></pre><p>Note, the docs warn that by using the <code>CASCADE</code> keyword, later, when we drop or update objects, the changes that cascade will not be listed. So, it should be used cautiously.</p><p>Using the table statements from <strong>Step 1</strong>, we get the following <code>FOREIGN KEY</code> constraint-statements:</p><pre class="bt-code"><code>ALTER TABLE food_des ADD CONSTRAINT fk__food_des__fd_group FOREIGN KEY (fdgrp_cd) REFERENCES fd_group (fdgrp_cd) ON DELETE CASCADE;</code><br /><br /><code>ALTER TABLE nut_data ADD CONSTRAINT fk__nut_data__nutr_def FOREIGN KEY (nutr_no) REFERENCES nutr_def (nutr_no) ON DELETE CASCADE;</code><br /><code>ALTER TABLE nut_data ADD CONSTRAINT fk__nut_data__src_cd FOREIGN KEY (src_cd) REFERENCES src_cd (src_cd) ON DELETE CASCADE;</code><br /><code>ALTER TABLE nut_data ADD CONSTRAINT fk__nut_data__deriv_cd FOREIGN KEY (deriv_cd) REFERENCES deriv_cd (deriv_cd) ON DELETE CASCADE;</code><br /><code>ALTER TABLE nut_data ADD CONSTRAINT fk__nut_data__food_des FOREIGN KEY (ndb_no) REFERENCES food_des (ndb_no) ON DELETE CASCADE;</code><br /><br /><code>ALTER TABLE datsrcln ADD CONSTRAINT fk__datsrcln__data_src FOREIGN KEY (datasrc_id) REFERENCES data_src (datasrc_id) ON DELETE CASCADE;</code><br /><code>ALTER TABLE datsrcln ADD CONSTRAINT fk__datsrcln__nut_data FOREIGN KEY (ndb_no, nutr_no) REFERENCES nut_data (ndb_no, nutr_no) ON DELETE CASCADE;</code><br /><br /><code>ALTER TABLE weight ADD CONSTRAINT fk__weight__food_des FOREIGN KEY (ndb_no) REFERENCES food_des (ndb_no) ON DELETE CASCADE;</code><br /><br /><code>ALTER TABLE langual ADD CONSTRAINT fk__langual__langdesc FOREIGN KEY (factor_code) REFERENCES langdesc (factor_code) ON DELETE CASCADE;</code><br /><code>ALTER TABLE langual ADD CONSTRAINT fk__langual__food_des FOREIGN KEY (ndb_no) REFERENCES food_des (ndb_no) ON DELETE CASCADE;</code></pre><p>Copy and paste these statements into the <em>Cockroach SQL interface</em>.</p><p>Now, we have the final-state of the desired product. So, let\'s exit out of the <em>Cockroach SQL interface</em> by pressing <code>Ctrl + D</code> on the keyboard. Next, let\'s convert this <em>Docker</em> container into a more permanent format, a <em>Docker</em> image.</p><h3>Step 6. Convert Into Docker Image</h3><p>Since we already have the container <code>cockroach_usdadb</code> up-and-running in the other terminal window, we can simply run the following command to convert that container into a <em>Docker</em> image:</p><pre class="bt-cmd-in"><code>docker commit cockroach_usdadb cockroach_usdadb:latest</code></pre><p>Now, if we run the following command:</p><pre class="bt-cmd-in"><code>docker images</code></pre><p>We should should expect to see something similar to the following:</p><pre class="bt-cmd-out"><code>REPOSITORY         TAG      IMAGE ID       CREATED          SIZE</code><br /><code>cockroach_usdadb   latest   909c247ef4ca   21 seconds ago   383MB</code></pre><h3>Conclusion</h3><p>This tutorial demonstrated how to import CSV data into <em>CockroachDB</em> by creating a simple file-server using <em>Caddy</em>. Although this tutorial used <em>Docker</em> for demonstration purposes, the same steps can be applied to an actual <em>CockroachDB</em> server. The <em>CockroachDB</em> server would simply need to be able to reach the simple-file server.</p><p>The final-version of this image was uploaded to <em>Docker-Hub</em> and it was made public. So, if you would like, you can simply pull and run this image locally without needing to follow the steps taken in this tutorial. <a href="https://hub.docker.com/r/lovohh/cockroach_usdadb/">The docker image <strong>lovohh/cockroach_usdadb</strong> can be located here</a>. If you wish to run this <em>Docker image</em> locally, run the following command:</p><pre class="bt-cmd-in"><code>docker run -d -p 8080:8080 lovohh/cockroach_usdadb</code></pre><h3>What\'s Next?</h3><p>In a future tutorial, we will be using the final-version of this <em>Docker</em> image to create a relatively small API. The tutorial for making that app will be linked here when it has been made available.</p>\n',
  15,
  0
);
